#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
MedRAGæ£€ç´¢å¢å¼ºæ¨¡å—
ä¸ºåŒ»ç–—VQAç³»ç»Ÿæä¾›ç›¸å…³åŒ»ç–—çŸ¥è¯†æ£€ç´¢åŠŸèƒ½
"""

import os
import json
import numpy as np
from typing import List, Dict, Tuple, Optional
from collections import defaultdict
import pickle
from sentence_transformers import SentenceTransformer
import torch
from tqdm import tqdm


class MedicalKnowledgeBase:
    """åŒ»ç–—çŸ¥è¯†åº“ç±»"""
    
    def __init__(self, knowledge_path: str = None, embedding_model: str = "sentence-transformers/all-MiniLM-L6-v2"):
        """
        åˆå§‹åŒ–åŒ»ç–—çŸ¥è¯†åº“
        
        Args:
            knowledge_path: çŸ¥è¯†åº“æ–‡ä»¶è·¯å¾„
            embedding_model: åµŒå…¥æ¨¡å‹åç§°
        """
        self.knowledge_path = knowledge_path
        self.embedding_model_name = embedding_model
        self.embedding_model = None
        self.knowledge_docs = []
        self.embeddings = None
        self.doc_index = {}
        
    def load_embedding_model(self):
        """åŠ è½½åµŒå…¥æ¨¡å‹"""
        print(f"ğŸ”¹ åŠ è½½åµŒå…¥æ¨¡å‹: {self.embedding_model_name}")
        try:
            self.embedding_model = SentenceTransformer(self.embedding_model_name)
            if torch.cuda.is_available():
                self.embedding_model = self.embedding_model.cuda()
            print("âœ… åµŒå…¥æ¨¡å‹åŠ è½½æˆåŠŸ")
        except Exception as e:
            print(f"âŒ åµŒå…¥æ¨¡å‹åŠ è½½å¤±è´¥: {e}")
            raise
    
    def load_medical_knowledge(self, knowledge_path: str = None):
        """åŠ è½½åŒ»ç–—çŸ¥è¯†åº“"""
        if knowledge_path:
            self.knowledge_path = knowledge_path
            
        if not self.knowledge_path or not os.path.exists(self.knowledge_path):
            print("âš ï¸  æœªæ‰¾åˆ°çŸ¥è¯†åº“æ–‡ä»¶ï¼Œå°†åˆ›å»ºé»˜è®¤çŸ¥è¯†åº“")
            self.create_default_knowledge_base()
            return
            
        print(f"ğŸ”¹ åŠ è½½åŒ»ç–—çŸ¥è¯†åº“: {self.knowledge_path}")
        
        try:
            if self.knowledge_path.endswith('.json'):
                with open(self.knowledge_path, 'r', encoding='utf-8') as f:
                    data = json.load(f)
                    if isinstance(data, list):
                        self.knowledge_docs = data
                    else:
                        self.knowledge_docs = [data]
            elif self.knowledge_path.endswith('.jsonl'):
                with open(self.knowledge_path, 'r', encoding='utf-8') as f:
                    for line in f:
                        if line.strip():
                            self.knowledge_docs.append(json.loads(line))
            
            print(f"âœ… æˆåŠŸåŠ è½½ {len(self.knowledge_docs)} æ¡åŒ»ç–—çŸ¥è¯†")
            
        except Exception as e:
            print(f"âŒ çŸ¥è¯†åº“åŠ è½½å¤±è´¥: {e}")
            print("åˆ›å»ºé»˜è®¤çŸ¥è¯†åº“...")
            self.create_default_knowledge_base()
    
    def create_default_knowledge_base(self):
        """åˆ›å»ºé»˜è®¤åŒ»ç–—çŸ¥è¯†åº“"""
        print("ğŸ”¹ åˆ›å»ºé»˜è®¤åŒ»ç–—çŸ¥è¯†åº“...")
        self.knowledge_docs = [
            {
                "id": "cardio_basic_1",
                "title": "å¿ƒè¡€ç®¡ç³»ç»ŸåŸºç¡€",
                "content": "å¿ƒè¡€ç®¡ç³»ç»ŸåŒ…æ‹¬å¿ƒè„ã€è¡€ç®¡å’Œè¡€æ¶²ã€‚å¿ƒè„æ˜¯å¾ªç¯ç³»ç»Ÿçš„ä¸­å¿ƒï¼Œè´Ÿè´£æ³µè¡€åˆ°å…¨èº«å„ä¸ªå™¨å®˜å’Œç»„ç»‡ã€‚å¿ƒè¡€ç®¡ç–¾ç—…å¸¸è§çš„ç—‡çŠ¶åŒ…æ‹¬èƒ¸ç—›ã€å‘¼å¸å›°éš¾ã€å¿ƒæ‚¸ã€ç–²åŠ³ç­‰ã€‚",
                "category": "cardiovascular",
                "keywords": ["å¿ƒè„", "è¡€ç®¡", "è¡€æ¶²å¾ªç¯", "èƒ¸ç—›", "å‘¼å¸å›°éš¾"]
            },
            {
                "id": "respiratory_basic_1", 
                "title": "å‘¼å¸ç³»ç»ŸåŸºç¡€",
                "content": "å‘¼å¸ç³»ç»ŸåŒ…æ‹¬é¼»è…”ã€å’½ã€å–‰ã€æ°”ç®¡ã€æ”¯æ°”ç®¡å’Œè‚ºã€‚ä¸»è¦åŠŸèƒ½æ˜¯è¿›è¡Œæ°”ä½“äº¤æ¢ï¼Œä¸ºèº«ä½“æä¾›æ°§æ°”å¹¶æ’å‡ºäºŒæ°§åŒ–ç¢³ã€‚å¸¸è§å‘¼å¸ç³»ç»Ÿç–¾ç—…åŒ…æ‹¬å“®å–˜ã€æ…¢æ€§é˜»å¡æ€§è‚ºç—…(COPD)ã€è‚ºç‚ç­‰ã€‚",
                "category": "respiratory",
                "keywords": ["å‘¼å¸", "è‚º", "æ°”ç®¡", "COPD", "å“®å–˜"]
            },
            {
                "id": "diagnosis_imaging_1",
                "title": "å½±åƒè¯Šæ–­æ£€æŸ¥",
                "content": "åŒ»å­¦å½±åƒæ£€æŸ¥åŒ…æ‹¬Xå…‰ç‰‡ã€CTã€MRIã€è¶…å£°ç­‰ã€‚èƒ¸éƒ¨Xå…‰æ˜¯è¯„ä¼°è‚ºéƒ¨å’Œå¿ƒè„çš„åŸºæœ¬æ£€æŸ¥ã€‚CTæ‰«æèƒ½æä¾›æ›´è¯¦ç»†çš„æ¨ªæˆªé¢å›¾åƒã€‚MRIé€‚ç”¨äºè½¯ç»„ç»‡æˆåƒã€‚è¶…å£°æ£€æŸ¥æ— è¾å°„ï¼Œé€‚åˆåŠ¨æ€è§‚å¯Ÿã€‚",
                "category": "diagnosis",
                "keywords": ["Xå…‰", "CT", "MRI", "è¶…å£°", "å½±åƒè¯Šæ–­"]
            },
            {
                "id": "emergency_medicine_1",
                "title": "æ€¥è¯ŠåŒ»å­¦åŸåˆ™", 
                "content": "æ€¥è¯ŠåŒ»å­¦éµå¾ªABCåŸåˆ™ï¼šæ°”é“(Airway)ã€å‘¼å¸(Breathing)ã€å¾ªç¯(Circulation)ã€‚ç´§æ€¥æƒ…å†µä¸‹éœ€è¦å¿«é€Ÿè¯„ä¼°ç”Ÿå‘½ä½“å¾ï¼ŒåŒ…æ‹¬è¡€å‹ã€å¿ƒç‡ã€å‘¼å¸é¢‘ç‡ã€ä½“æ¸©å’Œè¡€æ°§é¥±å’Œåº¦ã€‚",
                "category": "emergency",
                "keywords": ["æ€¥è¯Š", "ç”Ÿå‘½ä½“å¾", "ABCåŸåˆ™", "è¡€å‹", "å¿ƒç‡"]
            },
            {
                "id": "lab_tests_1",
                "title": "å®éªŒå®¤æ£€æŸ¥",
                "content": "å¸¸ç”¨å®éªŒå®¤æ£€æŸ¥åŒ…æ‹¬è¡€å¸¸è§„(CBC)ã€ç”ŸåŒ–æ£€æŸ¥ã€å‡è¡€åŠŸèƒ½ã€å¿ƒè‚Œæ ‡å¿—ç‰©ç­‰ã€‚D-äºŒèšä½“ç”¨äºè¯„ä¼°è¡€æ “é£é™©ã€‚è‚Œé’™è›‹ç™½æ˜¯å¿ƒè‚ŒæŸä¼¤çš„ç‰¹å¼‚æ€§æ ‡å¿—ç‰©ã€‚è‚åŠŸèƒ½æ£€æŸ¥åŒ…æ‹¬ALTã€ASTã€èƒ†çº¢ç´ ç­‰ã€‚",
                "category": "laboratory", 
                "keywords": ["è¡€å¸¸è§„", "D-äºŒèšä½“", "è‚Œé’™è›‹ç™½", "è‚åŠŸèƒ½", "å‡è¡€åŠŸèƒ½"]
            }
        ]
        print(f"âœ… åˆ›å»ºäº† {len(self.knowledge_docs)} æ¡é»˜è®¤åŒ»ç–—çŸ¥è¯†")
    
    def build_embeddings(self):
        """æ„å»ºçŸ¥è¯†åº“çš„åµŒå…¥å‘é‡"""
        if not self.embedding_model:
            self.load_embedding_model()
            
        print("ğŸ”¹ æ„å»ºçŸ¥è¯†åº“åµŒå…¥å‘é‡...")
        
        # ä¸ºæ¯ä¸ªçŸ¥è¯†æ–‡æ¡£åˆ›å»ºæ–‡æœ¬è¡¨ç¤º
        texts = []
        for i, doc in enumerate(self.knowledge_docs):
            # ç»„åˆæ ‡é¢˜ã€å†…å®¹å’Œå…³é”®è¯
            text = f"{doc.get('title', '')}\n{doc.get('content', '')}"
            if 'keywords' in doc:
                text += f"\nå…³é”®è¯: {', '.join(doc['keywords'])}"
            texts.append(text)
            self.doc_index[i] = doc.get('id', f'doc_{i}')
        
        # è®¡ç®—åµŒå…¥å‘é‡
        embeddings = []
        batch_size = 32
        for i in tqdm(range(0, len(texts), batch_size), desc="è®¡ç®—åµŒå…¥"):
            batch_texts = texts[i:i+batch_size]
            batch_embeddings = self.embedding_model.encode(batch_texts, convert_to_tensor=True)
            embeddings.append(batch_embeddings.cpu().numpy())
        
        self.embeddings = np.vstack(embeddings)
        print(f"âœ… æˆåŠŸæ„å»º {self.embeddings.shape[0]} ä¸ªåµŒå…¥å‘é‡")


class MedRAGRetriever:
    """åŒ»ç–—æ£€ç´¢å¢å¼ºç”Ÿæˆå™¨"""
    
    def __init__(self, knowledge_base: MedicalKnowledgeBase):
        """
        åˆå§‹åŒ–MedRAGæ£€ç´¢å™¨
        
        Args:
            knowledge_base: åŒ»ç–—çŸ¥è¯†åº“å®ä¾‹
        """
        self.kb = knowledge_base
        
    def retrieve_relevant_docs(self, query: str, question: str, options: Dict, 
                             medical_task: str = "", body_system: str = "", 
                             top_k: int = 3) -> List[Dict]:
        """
        æ£€ç´¢ç›¸å…³åŒ»ç–—æ–‡æ¡£
        
        Args:
            query: æŸ¥è¯¢æ–‡æœ¬
            question: åŒ»ç–—é—®é¢˜
            options: é€‰é¡¹å­—å…¸
            medical_task: åŒ»ç–—ä»»åŠ¡ç±»å‹
            body_system: èº«ä½“ç³»ç»Ÿ
            top_k: è¿”å›çš„æ–‡æ¡£æ•°é‡
            
        Returns:
            ç›¸å…³æ–‡æ¡£åˆ—è¡¨
        """
        if not self.kb.embedding_model or self.kb.embeddings is None:
            print("âš ï¸  çŸ¥è¯†åº“æœªåˆå§‹åŒ–ï¼Œè·³è¿‡æ£€ç´¢")
            return []
        
        # æ„å»ºæŸ¥è¯¢æ–‡æœ¬
        query_text = self.build_query_text(query, question, options, medical_task, body_system)
        
        # è®¡ç®—æŸ¥è¯¢åµŒå…¥
        query_embedding = self.kb.embedding_model.encode([query_text], convert_to_tensor=True)
        if torch.cuda.is_available():
            query_embedding = query_embedding.cuda()
        
        # è®¡ç®—ç›¸ä¼¼åº¦
        query_embedding = query_embedding.cpu().numpy()
        similarities = np.dot(self.kb.embeddings, query_embedding.T).flatten()
        
        # è·å–æœ€ç›¸å…³çš„æ–‡æ¡£
        top_indices = np.argsort(similarities)[::-1][:top_k]
        
        relevant_docs = []
        for idx in top_indices:
            if similarities[idx] > 0.3:  # ç›¸ä¼¼åº¦é˜ˆå€¼
                doc = self.kb.knowledge_docs[idx].copy()
                doc['similarity_score'] = float(similarities[idx])
                relevant_docs.append(doc)
        
        return relevant_docs
    
    def build_query_text(self, query: str, question: str, options: Dict, 
                        medical_task: str, body_system: str) -> str:
        """æ„å»ºæŸ¥è¯¢æ–‡æœ¬"""
        # æå–å…³é”®è¯
        keywords = []
        
        # ä»åŒ»ç–—ä»»åŠ¡å’Œèº«ä½“ç³»ç»Ÿæå–å…³é”®è¯
        if medical_task:
            keywords.append(medical_task)
        if body_system:
            keywords.append(body_system)
            
        # ä»é€‰é¡¹å†…å®¹æå–å…³é”®è¯
        option_texts = []
        for key, value in options.items():
            option_texts.append(value)
        
        # ç»„åˆæŸ¥è¯¢æ–‡æœ¬
        query_parts = [query, question]
        if keywords:
            query_parts.append(" ".join(keywords))
        if option_texts:
            query_parts.extend(option_texts)
            
        return " ".join(query_parts)
    
    def format_retrieved_docs(self, docs: List[Dict]) -> str:
        """æ ¼å¼åŒ–æ£€ç´¢åˆ°çš„æ–‡æ¡£ä¸ºæ–‡æœ¬"""
        if not docs:
            return ""
        
        formatted_text = "\n## ç›¸å…³åŒ»ç–—çŸ¥è¯†:\n"
        for i, doc in enumerate(docs, 1):
            formatted_text += f"{i}. **{doc.get('title', 'æœªçŸ¥æ ‡é¢˜')}** (ç›¸å…³åº¦: {doc.get('similarity_score', 0):.3f})\n"
            formatted_text += f"   {doc.get('content', '')}\n"
            if 'keywords' in doc:
                formatted_text += f"   å…³é”®è¯: {', '.join(doc['keywords'])}\n"
            formatted_text += "\n"
        
        return formatted_text


def create_medrag_system(knowledge_path: str = None, embedding_model: str = None) -> Tuple[MedicalKnowledgeBase, MedRAGRetriever]:
    """
    åˆ›å»ºMedRAGç³»ç»Ÿçš„ä¾¿æ·å‡½æ•°
    
    Args:
        knowledge_path: çŸ¥è¯†åº“è·¯å¾„
        embedding_model: åµŒå…¥æ¨¡å‹åç§°
        
    Returns:
        (çŸ¥è¯†åº“, æ£€ç´¢å™¨) å…ƒç»„
    """
    # åˆå§‹åŒ–çŸ¥è¯†åº“
    kb = MedicalKnowledgeBase(knowledge_path, embedding_model or "sentence-transformers/all-MiniLM-L6-v2")
    kb.load_medical_knowledge()
    kb.build_embeddings()
    
    # åˆå§‹åŒ–æ£€ç´¢å™¨
    retriever = MedRAGRetriever(kb)
    
    return kb, retriever
