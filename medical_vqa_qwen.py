#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
åŸºäºQWEN2.5-VL-3B-INSTRUCTçš„åŒ»ç–—è§†è§‰é—®ç­”ç³»ç»Ÿ
é€‚é…åŒ»ç–—æ•°æ®æ ¼å¼ï¼Œæ”¯æŒå•ä¸ªé—®é¢˜å’Œæ‰¹é‡å¤„ç†
"""

import os
import json
import time
import torch
import argparse
from tqdm import tqdm
from PIL import Image
from transformers import AutoProcessor, AutoModelForVision2Seq
from typing import Dict, List, Tuple, Optional


class MedicalVQA:
    def __init__(self, model_path: str, device: str = None):
        """
        åˆå§‹åŒ–åŒ»ç–—VQAç³»ç»Ÿ
        
        Args:
            model_path: QWEN2.5-VL-3Bæ¨¡å‹è·¯å¾„
            device: è¿è¡Œè®¾å¤‡ï¼ŒNoneä¸ºè‡ªåŠ¨æ£€æµ‹
        """
        self.model_path = model_path
        self.device = device or ("cuda" if torch.cuda.is_available() else "cpu")
        self.processor = None
        self.model = None
        
    def load_model(self):
        """åŠ è½½QWEN2.5-VLæ¨¡å‹å’Œå¤„ç†å™¨"""
        print(f"ğŸ”¹ æ­£åœ¨åŠ è½½QWEN2.5-VLæ¨¡å‹: {self.model_path}")
        print(f"ğŸ”¹ ä½¿ç”¨è®¾å¤‡: {self.device}")
        
        try:
            # åŠ è½½å¤„ç†å™¨
            self.processor = AutoProcessor.from_pretrained(
                self.model_path,
                trust_remote_code=True,
                use_fast=False
            )
            
            # åŠ è½½æ¨¡å‹
            try:
                # å°è¯•ä½¿ç”¨é‡åŒ–é…ç½®ä»¥èŠ‚çœæ˜¾å­˜
                from transformers import BitsAndBytesConfig
                bnb_config = BitsAndBytesConfig(
                    load_in_4bit=True,
                    bnb_4bit_use_double_quant=True,
                    bnb_4bit_quant_type="nf4",
                    bnb_4bit_compute_dtype=torch.float16
                )
                self.model = AutoModelForVision2Seq.from_pretrained(
                    self.model_path,
                    quantization_config=bnb_config if self.device == "cuda" else None,
                    dtype=torch.float16 if self.device == "cuda" else torch.float32,
                    device_map="auto" if self.device == "cuda" else None,
                    trust_remote_code=True
                )
            except (ImportError, ValueError, Exception) as e:
                print(f"âš ï¸  é‡åŒ–åŠ è½½å¤±è´¥ï¼Œä½¿ç”¨æ ‡å‡†åŠ è½½: {e}")
                self.model = AutoModelForVision2Seq.from_pretrained(
                    self.model_path,
                    dtype=torch.float16 if self.device == "cuda" else torch.float32,
                    device_map="auto" if self.device == "cuda" else None,
                    trust_remote_code=True
                )
            
            if self.device != "cuda":
                self.model = self.model.to(self.device)
                
            self.model.eval()
            
            # è·å–å›¾åƒæ ‡è®° - ç›´æ¥ä½¿ç”¨processorçš„å±æ€§
            try:
                self.image_token = getattr(self.processor, "image_token", "<|image_pad|>")
                self.image_token_id = getattr(self.processor, "image_token_id", None)
                
                # å¦‚æœprocessoræ²¡æœ‰ç›´æ¥æä¾›image_token_idï¼Œå°è¯•è½¬æ¢
                if self.image_token_id is None:
                    self.image_token_id = self.processor.tokenizer.convert_tokens_to_ids(self.image_token)
                
                if self.image_token_id is None or self.image_token_id == self.processor.tokenizer.unk_token_id:
                    print(f"âš ï¸  æ— æ³•è·å–æœ‰æ•ˆçš„å›¾åƒæ ‡è®°IDï¼Œå°†è·³è¿‡æ ‡è®°éªŒè¯")
                else:
                    print(f"âœ… å›¾åƒæ ‡è®°: '{self.image_token}' (ID: {self.image_token_id})")
                    
            except Exception as e:
                print(f"âš ï¸  å›¾åƒæ ‡è®°è·å–å¤±è´¥: {e}")
                self.image_token_id = None
                
            print(f"âœ… æ¨¡å‹åŠ è½½æˆåŠŸ!")
            
        except Exception as e:
            print(f"âŒ æ¨¡å‹åŠ è½½å¤±è´¥: {e}")
            raise

    def load_images(self, image_names: List[str], image_folder: str) -> Tuple[List[Image.Image], List[str], List[str]]:
        """
        åŠ è½½å›¾åƒæ–‡ä»¶å¹¶è¿›è¡Œé¢„å¤„ç†
        
        Args:
            image_names: å›¾åƒæ–‡ä»¶ååˆ—è¡¨
            image_folder: å›¾åƒæ–‡ä»¶å¤¹è·¯å¾„
            
        Returns:
            å›¾åƒå¯¹è±¡åˆ—è¡¨, è·¯å¾„åˆ—è¡¨, é”™è¯¯ä¿¡æ¯åˆ—è¡¨
        """
        images = []
        paths = []
        errors = []
        target_size = (512, 512)  # ç»Ÿä¸€å›¾åƒå°ºå¯¸
        
        for name in image_names:
            path = os.path.join(image_folder, name)
            if not os.path.exists(path):
                errors.append(f"å›¾åƒä¸å­˜åœ¨: {path}")
                continue
                
            try:
                img = Image.open(path).convert("RGB")
                # å›¾åƒé¢„å¤„ç†ï¼šç»Ÿä¸€å°ºå¯¸
                img.thumbnail(target_size, Image.Resampling.LANCZOS)
                new_img = Image.new("RGB", target_size, (255, 255, 255))
                new_img.paste(img, ((target_size[0]-img.size[0])//2, (target_size[1]-img.size[1])//2))
                images.append(new_img)
                paths.append(path)
            except Exception as e:
                errors.append(f"åŠ è½½å¤±è´¥: {path} - {str(e)}")
                
        return images, paths, errors

    def build_vqa_prompt(self, question: str, options: Dict, images: List, medical_task: str = "", body_system: str = "") -> str:
        """
        æ„å»ºåŒ»ç–—VQAçš„æç¤ºè¯
        
        Args:
            question: åŒ»ç–—é—®é¢˜
            options: é€‰é¡¹å­—å…¸ {"A": "é€‰é¡¹å†…å®¹", "B": "é€‰é¡¹å†…å®¹", ...}
            images: å›¾åƒåˆ—è¡¨
            medical_task: åŒ»ç–—ä»»åŠ¡ç±»å‹
            body_system: èº«ä½“ç³»ç»Ÿ
            
        Returns:
            æ ¼å¼åŒ–çš„æç¤ºè¯
        """
        # ç”Ÿæˆå›¾åƒæ ‡è®°ï¼ˆæ¯ä¸ªå›¾åƒå¯¹åº”ä¸€ä¸ªæ ‡è®°ï¼Œä¸å·¥ä½œä»£ç ä¿æŒä¸€è‡´ï¼‰
        image_tokens_str = ""
        if hasattr(self, 'image_token') and self.image_token and images:
            image_tokens_str = "\n".join([self.image_token for _ in range(len(images))])
        
        # æ ¼å¼åŒ–é€‰é¡¹
        options_str = "\n".join([f"  {k}. {v}" for k, v in options.items()])
        
        # æ„å»ºåŒ»ç–—ä¸“ä¸šæç¤ºè¯ï¼ˆä¸å·¥ä½œä»£ç æ ¼å¼ä¿æŒä¸€è‡´ï¼‰
        prompt = f"""{image_tokens_str}
# åŒ»ç–—å›¾åƒé—®ç­”ä»»åŠ¡
åŒ»ç–—ä»»åŠ¡: {medical_task if medical_task else "åŒ»ç–—è¯Šæ–­"}
æ¶‰åŠç³»ç»Ÿ: {body_system if body_system else "å…¨èº«å„ç³»ç»Ÿ"}
é—®é¢˜: {question}
é€‰é¡¹ï¼š
{options_str}

# è¾“å‡ºè¦æ±‚
1. ä»”ç»†åˆ†æå›¾åƒä¸­çš„å…³é”®ä¿¡æ¯
2. ç»“åˆç—…ä¾‹æè¿°çš„ä¸´åºŠç—‡çŠ¶å’Œä½“å¾
3. åŸºäºåŒ»å­¦çŸ¥è¯†å’Œç»éªŒåšå‡ºåˆ¤æ–­
4. åªå›ç­”é€‰é¡¹å­—æ¯ï¼ˆå¦‚Aã€Bã€Cã€Dã€Eï¼‰ï¼Œä¸è¦æ·»åŠ å…¶ä»–å†…å®¹

ç­”æ¡ˆ:"""

        return prompt

    def build_multimodal_input(self, images: List[Image.Image], prompt: str) -> List:
        """
        æ„å»ºå¤šæ¨¡æ€è¾“å…¥åºåˆ—
        
        Args:
            images: å›¾åƒåˆ—è¡¨
            prompt: æ–‡æœ¬æç¤ºè¯
            
        Returns:
            å¤šæ¨¡æ€è¾“å…¥åºåˆ—
        """
        input_sequence = []
        
        # æ·»åŠ å›¾åƒ
        for img in images:
            input_sequence.append(img)
        
        # æ·»åŠ æ–‡æœ¬
        input_sequence.append(prompt)
        
        return input_sequence

    def predict_single(self, data_item: Dict, image_folder: str) -> Dict:
        """
        é¢„æµ‹å•ä¸ªåŒ»ç–—VQAæ ·æœ¬
        
        Args:
            data_item: æ•°æ®æ ·æœ¬å­—å…¸
            image_folder: å›¾åƒæ–‡ä»¶å¤¹è·¯å¾„
            
        Returns:
            é¢„æµ‹ç»“æœå­—å…¸
        """
        if self.model is None or self.processor is None:
            raise ValueError("æ¨¡å‹æœªåŠ è½½ï¼Œè¯·å…ˆè°ƒç”¨load_model()æ–¹æ³•")
            
        sample_id = data_item.get("id", "unknown")
        question = data_item.get("question", "")
        image_names = data_item.get("images", [])
        options = data_item.get("options", {})
        true_label = data_item.get("label", "")
        medical_task = data_item.get("medical_task", "")
        body_system = data_item.get("body_system", "")
        
        # æ•°æ®éªŒè¯
        if not question:
            return {
                "id": sample_id,
                "error": "é—®é¢˜ä¸ºç©º",
                "success": False
            }
            
        if not image_names:
            return {
                "id": sample_id,
                "error": "æ— å›¾åƒ",
                "success": False
            }
            
        # åŠ è½½å›¾åƒ
        images, img_paths, img_errors = self.load_images(image_names, image_folder)
        if img_errors:
            return {
                "id": sample_id,
                "error": f"å›¾åƒåŠ è½½é”™è¯¯: {'; '.join(img_errors)}",
                "success": False,
                "image_errors": img_errors
            }
            
        # æ„å»ºæç¤ºè¯
        prompt = self.build_vqa_prompt(question, options, images, medical_task, body_system)
        
        try:
            # å¤„ç†è¾“å…¥ - ä½¿ç”¨separateå‚æ•°æ–¹å¼ï¼ˆå·²éªŒè¯å¯ç”¨ï¼‰
            inputs = self.processor(
                text=prompt,
                images=images,
                return_tensors="pt",
                padding=True
            ).to(self.device, dtype=torch.float16 if self.device == "cuda" else torch.float32)
            
            # éªŒè¯è¾“å…¥å¤„ç†æˆåŠŸ
            if hasattr(self, 'image_token_id') and self.image_token_id is not None:
                try:
                    input_ids = inputs["input_ids"][0].cpu().numpy()
                    token_count = (input_ids == self.image_token_id).sum()
                    expected_tokens = len(images)
                    print(f"ğŸ” è¾“å…¥å¤„ç†æˆåŠŸ: æ£€æµ‹åˆ° {token_count} ä¸ªå›¾åƒæ ‡è®°, {len(images)} ä¸ªå›¾åƒ")
                    # æ³¨æ„ï¼šQWEN2.5-VLå¯èƒ½å°†1ä¸ªå›¾åƒåˆ†è§£æˆå¤šä¸ªç‰¹å¾æ ‡è®°ï¼Œè¿™æ˜¯æ­£å¸¸çš„
                except Exception as e:
                    print(f"ğŸ” è¾“å…¥éªŒè¯å¤±è´¥: {e}")
            
            # æ¨¡å‹æ¨ç†
            with torch.no_grad():
                outputs = self.model.generate(
                    **inputs,
                    max_new_tokens=32,
                    num_beams=1,
                    do_sample=False,
                    pad_token_id=self.processor.tokenizer.pad_token_id,
                    eos_token_id=self.processor.tokenizer.eos_token_id,
                    temperature=0.0
                )
            
            # è§£ç ç»“æœ - ä½¿ç”¨tokenizerç›´æ¥è§£ç 
            pred_raw = self.processor.tokenizer.decode(
                outputs[0],
                skip_special_tokens=True
            ).strip()
            
            # æå–é¢„æµ‹é€‰é¡¹
            pred_label = self.extract_option(pred_raw, options)
            is_correct = pred_label.upper() == true_label.upper()
            
            # è·å–é€‰é¡¹å†…å®¹
            pred_answer = options.get(pred_label.upper(), pred_raw)
            true_answer = options.get(true_label.upper(), "")
            
            return {
                "id": sample_id,
                "question": question,
                "images": img_paths,
                "prompt": prompt,
                "pred_raw": pred_raw,
                "pred_label": pred_label.upper(),
                "pred_answer": pred_answer,
                "true_label": true_label.upper(),
                "true_answer": true_answer,
                "correct": is_correct,
                "success": True
            }
            
        except Exception as e:
            return {
                "id": sample_id,
                "error": f"æ¨ç†å¤±è´¥: {str(e)}",
                "success": False
            }

    def extract_option(self, raw_text: str, options: Dict) -> str:
        """
        ä»åŸå§‹è¾“å‡ºä¸­æå–é€‰é¡¹æ ‡è¯†ç¬¦
        
        Args:
            raw_text: æ¨¡å‹åŸå§‹è¾“å‡º
            options: é€‰é¡¹å­—å…¸
            
        Returns:
            æå–çš„é€‰é¡¹æ ‡è¯†ç¬¦
        """
        raw_text = raw_text.upper().strip()
        
        # ç›´æ¥åŒ¹é…é€‰é¡¹å­—æ¯
        for option in options.keys():
            if option in raw_text:
                return option
                
        # å¦‚æœæ²¡æ‰¾åˆ°ï¼Œè¿”å›ç¬¬ä¸€ä¸ªæ‰¾åˆ°çš„é€‰é¡¹å­—æ¯
        import re
        matches = re.findall(r'[A-E]', raw_text)
        if matches:
            return matches[0]
            
        # é»˜è®¤è¿”å›åŸå§‹æ–‡æœ¬çš„æœ€åä¸€ä¸ªå­—ç¬¦ï¼ˆå¦‚æœæ˜¯é€‰é¡¹å­—æ¯ï¼‰
        if raw_text and raw_text[-1] in options:
            return raw_text[-1]
            
        return ""

    def predict_batch(self, data_path: str, image_folder: str, output_path: str = None) -> Dict:
        """
        æ‰¹é‡é¢„æµ‹åŒ»ç–—VQAæ•°æ®
        
        Args:
            data_path: æ•°æ®æ–‡ä»¶è·¯å¾„ï¼ˆJSONæˆ–JSONLæ ¼å¼ï¼‰
            image_folder: å›¾åƒæ–‡ä»¶å¤¹è·¯å¾„
            output_path: ç»“æœä¿å­˜è·¯å¾„
            
        Returns:
            ç»Ÿè®¡ç»“æœ
        """
        print(f"ğŸ”¹ å¼€å§‹æ‰¹é‡é¢„æµ‹: {data_path}")
        
        # åŠ è½½æ•°æ®
        samples = self.load_data(data_path)
        print(f"âœ… åŠ è½½æ ·æœ¬æ•°: {len(samples)}")
        
        results = []
        errors = []
        correct_count = 0
        
        start_time = time.time()
        
        for i, sample in enumerate(tqdm(samples, desc="é¢„æµ‹ä¸­")):
            result = self.predict_single(sample, image_folder)
            
            if result["success"]:
                results.append(result)
                if result.get("correct", False):
                    correct_count += 1
            else:
                errors.append(result)
                print(f"âŒ æ ·æœ¬ {result['id']}: {result.get('error', 'æœªçŸ¥é”™è¯¯')}")
        
        total_time = time.time() - start_time
        
        # ä¿å­˜ç»“æœ
        if output_path:
            self.save_results(results, errors, output_path)
        
        # ç»Ÿè®¡ä¿¡æ¯
        stats = {
            "total_samples": len(samples),
            "successful_predictions": len(results),
            "failed_predictions": len(errors),
            "correct_predictions": correct_count,
            "accuracy": correct_count / len(results) if results else 0,
            "total_time": total_time,
            "avg_time_per_sample": total_time / len(samples) if samples else 0
        }
        
        return stats

    def load_data(self, data_path: str) -> List[Dict]:
        """
        åŠ è½½æ•°æ®æ–‡ä»¶
        
        Args:
            data_path: æ•°æ®æ–‡ä»¶è·¯å¾„
            
        Returns:
            æ•°æ®æ ·æœ¬åˆ—è¡¨
        """
        samples = []
        
        if data_path.endswith('.jsonl'):
            # JSONLæ ¼å¼
            with open(data_path, 'r', encoding='utf-8') as f:
                for line in f:
                    if line.strip():
                        samples.append(json.loads(line))
        else:
            # JSONæ ¼å¼
            with open(data_path, 'r', encoding='utf-8') as f:
                data = json.load(f)
                if isinstance(data, list):
                    samples = data
                else:
                    samples = [data]
        
        return samples

    def save_results(self, results: List[Dict], errors: List[Dict], output_path: str):
        """
        ä¿å­˜é¢„æµ‹ç»“æœ
        
        Args:
            results: æˆåŠŸé¢„æµ‹ç»“æœåˆ—è¡¨
            errors: é”™è¯¯ä¿¡æ¯åˆ—è¡¨
            output_path: è¾“å‡ºæ–‡ä»¶è·¯å¾„
        """
        os.makedirs(os.path.dirname(output_path), exist_ok=True)
        
        # ä¿å­˜ä¸»è¦ç»“æœ
        with open(output_path, 'w', encoding='utf-8') as f:
            for result in results:
                f.write(json.dumps(result, ensure_ascii=False) + '\n')
        
        # ä¿å­˜é”™è¯¯æ—¥å¿—
        error_path = output_path.replace('.jsonl', '_errors.jsonl')
        with open(error_path, 'w', encoding='utf-8') as f:
            for error in errors:
                f.write(json.dumps(error, ensure_ascii=False) + '\n')
        
        print(f"âœ… ç»“æœå·²ä¿å­˜: {output_path}")
        print(f"âœ… é”™è¯¯æ—¥å¿—å·²ä¿å­˜: {error_path}")


def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(description="åŸºäºQWEN2.5-VLçš„åŒ»ç–—VQAç³»ç»Ÿ")
    parser.add_argument("--model_path", type=str, required=True, help="QWEN2.5-VLæ¨¡å‹è·¯å¾„")
    parser.add_argument("--data_path", type=str, help="æ•°æ®æ–‡ä»¶è·¯å¾„")
    parser.add_argument("--image_folder", type=str, help="å›¾åƒæ–‡ä»¶å¤¹è·¯å¾„")
    parser.add_argument("--output_path", type=str, default="medical_vqa_results.jsonl", help="è¾“å‡ºæ–‡ä»¶è·¯å¾„")
    parser.add_argument("--single_id", type=str, help="å¤„ç†å•ä¸ªæ ·æœ¬ID")
    parser.add_argument("--device", type=str, choices=["cuda", "cpu", "auto"], default="auto", help="è¿è¡Œè®¾å¤‡")
    
    args = parser.parse_args()
    
    # åˆå§‹åŒ–VQAç³»ç»Ÿ
    device = "cuda" if args.device == "auto" and torch.cuda.is_available() else args.device
    if device == "auto":
        device = "cuda" if torch.cuda.is_available() else "cpu"
    
    vqa_system = MedicalVQA(args.model_path, device)
    vqa_system.load_model()
    
    if args.single_id and args.data_path and args.image_folder:
        # å¤„ç†å•ä¸ªæ ·æœ¬
        samples = vqa_system.load_data(args.data_path)
        target_sample = None
        for sample in samples:
            if sample.get("id") == args.single_id:
                target_sample = sample
                break
        
        if target_sample:
            result = vqa_system.predict_single(target_sample, args.image_folder)
            print("\n=== å•æ ·æœ¬é¢„æµ‹ç»“æœ ===")
            print(json.dumps(result, ensure_ascii=False, indent=2))
        else:
            print(f"âŒ æœªæ‰¾åˆ°IDä¸º {args.single_id} çš„æ ·æœ¬")
    
    elif args.data_path and args.image_folder:
        # æ‰¹é‡å¤„ç†
        stats = vqa_system.predict_batch(args.data_path, args.image_folder, args.output_path)
        
        print("\n" + "="*60)
        print("ğŸ“Š æ‰¹é‡é¢„æµ‹ç»Ÿè®¡ç»“æœ:")
        print(f"æ€»æ ·æœ¬æ•°: {stats['total_samples']}")
        print(f"æˆåŠŸé¢„æµ‹: {stats['successful_predictions']}")
        print(f"å¤±è´¥é¢„æµ‹: {stats['failed_predictions']}")
        print(f"æ­£ç¡®é¢„æµ‹: {stats['correct_predictions']}")
        print(f"å‡†ç¡®ç‡: {stats['accuracy']:.4f}")
        print(f"æ€»è€—æ—¶: {stats['total_time']:.2f}ç§’")
        print(f"å¹³å‡è€—æ—¶: {stats['avg_time_per_sample']:.2f}ç§’/æ ·æœ¬")
        print("="*60)
    
    else:
        print("âŒ è¯·æä¾›æ•°æ®è·¯å¾„å’Œå›¾åƒæ–‡ä»¶å¤¹è·¯å¾„ï¼Œæˆ–æŒ‡å®šå•ä¸ªæ ·æœ¬ID")


if __name__ == "__main__":
    main()
